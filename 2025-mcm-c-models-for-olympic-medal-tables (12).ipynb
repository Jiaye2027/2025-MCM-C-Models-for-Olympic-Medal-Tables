{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10565479,"sourceType":"datasetVersion","datasetId":6537894},{"sourceId":10582230,"sourceType":"datasetVersion","datasetId":6548747}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom scipy import stats\nfrom scipy.stats import ttest_ind, norm\nfrom sklearn.feature_selection import mutual_info_regression\nfrom sklearn.neighbors import NearestNeighbors\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom sklearn.cluster import KMeans\nfrom sklearn.metrics import r2_score, mean_squared_error\n\nimport tensorflow as tf\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import r2_score\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Dense, Dropout, Add, BatchNormalization\nfrom tensorflow.keras.callbacks import EarlyStopping\nfrom tensorflow.keras.optimizers import Adam\nfrom sklearn.metrics import classification_report\nfrom tensorflow.keras.models import Sequential\nSEED = 42\nnp.random.seed(SEED)\nrandom.seed(SEED)\ntf.random.set_seed(SEED)\n\n\ndata_dict = pd.read_csv('/kaggle/input/2025-problem-c-data/2025_Problem_C_Data/data_dictionary.csv', encoding=\"latin-1\")\nathletes = pd.read_csv('/kaggle/input/2025-problem-c-data/2025_Problem_C_Data/summerOly_athletes.csv')\nhosts = pd.read_csv('/kaggle/input/2025-problem-c-data/2025_Problem_C_Data/summerOly_hosts.csv')\nmedal = pd.read_csv('/kaggle/input/2025-problem-c-data/2025_Problem_C_Data/summerOly_medal_counts.csv')\nprograms = pd.read_csv('/kaggle/input/2025-problem-c-data/2025_Problem_C_Data/summerOly_programs.csv', encoding=\"latin-1\")\nhosts = hosts.drop(hosts.index[hosts['Year'].isin([1916, 1940, 1944])]) #Drop years during WW\nathletes['NOC'] = athletes['NOC'].replace('AIN', 'ROC') #2024 ROC Team\nprograms.rename(columns={'1906*': '1906'}, inplace=True) #Replace 1906* as 1906\ny_2028_sports = pd.read_csv('/kaggle/input/programs2028/summerOly_2028_Sports.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:40:12.693662Z","iopub.execute_input":"2025-01-28T04:40:12.694181Z","iopub.status.idle":"2025-01-28T04:40:13.253964Z","shell.execute_reply.started":"2025-01-28T04:40:12.694139Z","shell.execute_reply":"2025-01-28T04:40:13.252984Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def medal_count_for_each_sport(athletes):\n    train = (\n        athletes[['Year', 'NOC', 'Sport', 'Event', 'Medal']]\n        .drop_duplicates()\n        .groupby(['Year', 'NOC', 'Sport', 'Medal'])\n        .size()\n        .unstack(fill_value=0)\n        .reset_index()\n    ).sort_values(by=['Year', 'Gold', 'Silver', 'Bronze'], ascending=[False, False, False, False])\n    \n    athlete_count = (\n        athletes[['Year', 'NOC', 'Sport', 'Name']]\n        .drop_duplicates()\n        .groupby(['Year', 'NOC', 'Sport'])\n        .size()\n        .reset_index(name='Athlete_Count')\n    )\n    \n    sport_athlete_count = (\n        athletes[['Year', 'Sport', 'Name']]\n        .drop_duplicates()\n        .groupby(['Year', 'Sport'])\n        .size()\n        .reset_index(name='Sport_Athlete_Count')\n    )\n\n    train = train.merge(athlete_count, on=['Year', 'NOC', 'Sport'], how='left')\n    train = train.merge(sport_athlete_count, on=['Year', 'Sport'], how='left')\n\n    train['Athlete_Proportion'] = train['Athlete_Count'] / train['Sport_Athlete_Count']\n\n    train = train.loc[:, ['Year', 'NOC', 'Sport', 'Gold', 'Silver', 'Bronze', 'Athlete_Count', 'Sport_Athlete_Count', 'Athlete_Proportion']]\n    return train.reset_index(drop=True)\n\ndef create_2028_rows(train):\n    df_2028 = train[(train['Year'] >= 1999)]\n    noc_sport_combinations = df_2028.groupby(['NOC', 'Sport']).size().reset_index()[['NOC', 'Sport']]\n    new_rows = pd.DataFrame({\n        'Year': 2028,\n        'NOC': noc_sport_combinations['NOC'],\n        'Sport': noc_sport_combinations['Sport'],\n        'Gold': 0,\n        'Silver': 0,\n        'Bronze': 0,\n        'Athlete_Count': 0,\n        'Sport_Athlete_Count': 0,\n        'Athlete_Proportion': 0.0\n    })\n\n    return pd.concat([new_rows, train], ignore_index=True)\n\ndef merge_hosts(train, hosts):\n    new_row = pd.DataFrame({'Year': [1906], 'Host': ['Athens, Greece']}) # Add 1906 Host\n    hosts = pd.concat([hosts, new_row], ignore_index=True)\n    \n    country_to_noc = {\n        \"United States\": \"USA\",\n        \"United Kingdom\": \"GBR\",\n        \"France\": \"FRA\",\n        \"Australia\": \"AUS\",\n        \"Japan\": \"JPN\",\n        \"Germany\": \"GER\",\n        \"Greece\": \"GRE\",\n        \"Brazil\": \"BRA\",\n        \"China\": \"CHN\",\n        \"Spain\": \"ESP\",\n        \"South Korea\": \"KOR\",\n        \"Russia\": \"RUS\",\n        \"Canada\": \"CAN\",\n        \"Mexico\": \"MEX\",\n        \"Italy\": \"ITA\",\n        \"Finland\": \"FIN\",\n        \"Netherlands\": \"NED\",\n        \"Belgium\": \"BEL\",\n        \"Sweden\": \"SWE\",\n    }    \n    hosts['Country'] = hosts['Host'].str.split(',').str[-1].str.strip()\n    hosts['NOC'] = hosts['Country'].map(country_to_noc)\n    hosts.loc[hosts['Year'] == 1972, 'NOC'] = 'FRG'\n    hosts.loc[hosts['Year'] == 1980, 'NOC'] = 'URS'\n    hosts.loc[hosts['Year'] == 2020, 'NOC'] = 'JPN'\n    hosts = hosts.drop(['Host', 'Country'], axis=1)\n\n    train = pd.merge(train, hosts, on='Year', how='left', suffixes=('', '_host'))\n    train['NOC'] = train['NOC'].replace({'RUS': 'ROC'})\n    train['NOC_host'] = train['NOC_host'].replace({'RUS': 'ROC'})\n    train['NOC_if_host'] = train.apply(lambda row: 1 if row['NOC'] == row['NOC_host'] else 0, axis=1)\n    return train\n\ndef add_2028_sports(programs, y_2028_sports):\n    programs['Discipline'] = programs['Discipline'].fillna(programs['Sport'])\n\n    programs['Sport'] = programs['Sport'].str.replace('\\xa0', ' ', regex=True)\n\n    programs['Sport'] = programs['Sport'].str.lower()\n    programs['Discipline'] = programs['Discipline'].str.lower()\n    y_2028_sports['Sport'] = y_2028_sports['Sport'].str.lower()\n    y_2028_sports['Discipline'] = y_2028_sports['Discipline'].str.lower()\n\n    if '2028' not in programs.columns:\n        programs = programs.merge(y_2028_sports, how='left', left_on=['Sport', 'Discipline'], right_on=['Sport', 'Discipline'])\n        programs['2028'] = programs['2028'].fillna(0).astype(int)\n        programs.loc[71, '2028'] = programs.loc[:70, '2028'].sum()\n    else:\n        print(\"2028 column already exists\")\n    return programs\n\ndef merge_programs(train, programs):\n    sport_to_code_mapping = {\n        'Athletics': 'ATH',\n        'Hockey': 'HOC',\n        'Football': 'FBL',\n        'Wrestling': 'WRG',\n        'Boxing': 'BOX',\n        'Judo': 'JUD',\n        'Taekwondo': 'TKW',\n        'Shooting': 'SHO',\n        'Swimming': 'SWM',\n        'Cycling Road': 'CRD',\n        'Weightlifting': 'WLF',\n        'Fencing': 'FEN',\n        'Synchronized Swimming': 'SWA',\n        'Sailing': 'SAL',\n        'Equestrianism': 'EDR',\n        'Triathlon': 'TRI',\n        'Cycling': 'CTR',\n        'Artistic Gymnastics': 'GAR',\n        'Gymnastics': 'GAR',\n        'Handball': 'HBL',\n        'Tennis': 'TEN',\n        'Volleyball': 'VVO',\n        'Rowing': 'ROW',\n        'Table Tennis': 'TTE',\n        'Trampolining': 'GTR',\n        'Badminton': 'BDM',\n        'Canoe Sprint': 'CSP',\n        'Karate': 'KTE',\n        'Marathon Swimming': 'OWS',\n        'Canoe Slalom': 'CSL',\n        'Canoeing': 'CSP', \n        'Basketball': 'BKB',\n        'Beach Volleyball': 'VBV',\n        'Rugby': 'RUG',\n        'Diving': 'DIV',\n        'Figure Skating': 'FSK',\n        'Polo': 'POL',\n        'Water Polo': 'WPO',\n        'Art Competitions': None,\n        'Modern Pentathlon': 'MPN',\n        'Archery': 'ARC',\n        'Golf': 'GLF',\n        'Rugby Sevens': 'RU7',\n        'Cycling BMX Racing': 'BMX',\n        'Cycling Mountain Bike': 'MTB',\n        'Equestrian': 'EDR',\n        'Surfing': 'SRF',\n        'Cycling BMX Freestyle': 'BMF',\n        'Skateboarding': 'SKB',\n        'Rhythmic Gymnastics': 'GRY',\n        'Softball': 'SBL',\n        'Baseball': 'BSB',\n        'Cycling Track': 'CTR',\n        'Artistic Swimming': 'SWA',\n        'Baseball/Softball': 'BSB',\n        'Sport Climbing': 'CLB',\n        'Trampoline Gymnastics': 'GTR',\n        '3x3 Basketball': 'BK3',\n        'Breaking': 'BKG',\n        'Tug-Of-War': 'TOW',\n        'Ice Hockey': 'IHO',\n        'Lacrosse': 'LAX',\n        'Basque Pelota': 'PEL',\n        'Croquet': 'CQT',\n        'Cricket': 'CKT',\n        'Motorboating': None,\n        'Racquets': 'RQT',\n        'Jeu De Paume': '\\x96',\n        'Alpinism': None, \n        'Aeronautics': None,\n        'Roque': 'ROC'\n    }\n    \n    train['Sport_Code'] = train['Sport'].map(sport_to_code_mapping)\n    train['Sport_Code'] = train['Sport_Code'].fillna('NAN')\n\n    year_columns = [str(year) for year in list(range(1896, 2025, 4)) + ['1906']]\n    for year_to_remove in ['1940', '1944', '1916']:\n        year_columns = [year for year in year_columns if year != year_to_remove]\n    \n    melted_programs = pd.melt(\n        programs,\n        id_vars=['Sport', 'Discipline', 'Code', 'Sports Governing Body'],\n        value_vars=year_columns,\n        var_name='Year',\n        value_name='Number_of_Events'\n    ).sort_values(by=['Year', 'Sport'], ascending=[False, True]).loc[:, ['Year', 'Code', 'Number_of_Events']].fillna(0)\n    \n    train['Year'] = train['Year'].astype(int)\n    melted_programs['Year'] = melted_programs['Year'].astype(int)\n    \n    merged_df = train.merge(\n        melted_programs,\n        left_on=['Year', 'Sport_Code'],\n        right_on=['Year', 'Code'],\n        how='left'\n    ).drop(['Sport','Code'], axis=1)\n    \n    return merged_df\n\ndef add_Medal_EWA(train):\n    GOLD_WEIGHT = 0.5\n    SILVER_WEIGHT = 0.3\n    BROUNZE_WEIGHT = 0.2\n    beta = 0.8\n\n    train['Number_of_Events'] = train['Number_of_Events'].fillna(0).astype(int)\n\n    condition = (train['Number_of_Events'] != 0)\n\n    train['current_year_value'] = 0\n    train.loc[condition, 'current_year_value'] = (\n        (GOLD_WEIGHT * train['Gold'] + SILVER_WEIGHT * train['Silver'] + BROUNZE_WEIGHT * train['Bronze']) /\n        (train['Number_of_Events']))\n    \n    train['Medal_EWA'] = 0\n\n    for noc, group in train.groupby(['NOC','Sport_Code']):\n        ewa = 0\n        t = 1\n        for idx, row in group.iterrows():\n            ewa = (beta * ewa + (1 - beta) * row['current_year_value']) / (1 - beta**t)\n            train.loc[idx, 'Medal_EWA'] = ewa\n            t += 1\n\n    train.drop(columns=['current_year_value'], inplace=True)\n    return train\n\ndef create_scores(train, athletes):\n    athletes_clean = athletes.drop_duplicates(subset=['Year', 'NOC', 'Name'])\n    athletes_sorted = athletes_clean.sort_values(by='Year')\n    athletes_sorted['participation_time'] = athletes_sorted.groupby(['NOC', 'Name'])['Year'] \\\n                                                           .rank(method='first', ascending=True) \\\n                                                           .astype(int)\n    athletes_sorted[['Name', 'NOC', 'Year', 'participation_time']]\n    \n    athletes_sorted['Medal_Count'] = (athletes_sorted['Medal'] != 'No medal').astype(int)\n    medal_distribution = athletes_sorted.groupby('participation_time')['Medal_Count'].sum().reset_index()\n    medal_distribution.columns = ['participation_time', 'Total_Medals']\n    medal_distribution['Medal_Probability'] = medal_distribution['Total_Medals'] / medal_distribution['Total_Medals'].sum()\n    \n    athletes_sorted = athletes_sorted.merge(\n        medal_distribution[['participation_time', 'Medal_Probability']],\n        on='participation_time',\n        how='left'\n    )\n    \n    athletes_sorted['Gold'] = (athletes_sorted['Medal'] == 'Gold').astype(int)\n    athletes_sorted['Silver'] = (athletes_sorted['Medal'] == 'Silver').astype(int)\n    athletes_sorted['Bronze'] = (athletes_sorted['Medal'] == 'Bronze').astype(int)\n    athletes_sorted['Cumulative_Gold'] = athletes_sorted.groupby(['NOC', 'Name'])['Gold'].cumsum()\n    athletes_sorted['Cumulative_Silver'] = athletes_sorted.groupby(['NOC', 'Name'])['Silver'].cumsum()\n    athletes_sorted['Cumulative_Bronze'] = athletes_sorted.groupby(['NOC', 'Name'])['Bronze'].cumsum()\n    athletes_sorted_clean = athletes_sorted.drop_duplicates(subset=['Year', 'NOC', 'Name'])\n    \n    train_clean = train.drop_duplicates(subset=['Year', 'NOC'])\n    \n    final_df = train_clean.merge(\n        athletes_sorted_clean[['Year', 'NOC', 'Name', 'participation_time', 'Medal_Probability', \n                               'Cumulative_Gold', 'Cumulative_Silver', 'Cumulative_Bronze']],\n        on=['Year', 'NOC'],\n        how='left'\n    )\n    if 'Age' in athletes_sorted_clean.columns:\n        final_df = final_df.merge(\n            athletes_sorted_clean[['Name', 'Year', 'Age']],\n            on=['Name', 'Year'],\n            how='left'\n        )\n    final_df = final_df.rename(columns={\n        'participation_time': 'Age_Proxy',\n        'Medal_Probability': 'Medal_Probability_at_Age',\n        'Cumulative_Gold': 'Gold_Upto_Year',\n        'Cumulative_Silver': 'Silver_Upto_Year',\n        'Cumulative_Bronze': 'Bronze_Upto_Year'\n    })\n    final_df = final_df[final_df['Year']!=2028]\n    final_df = final_df[['Year', 'NOC', 'Name', 'Age_Proxy',\n                         'Medal_Probability_at_Age', 'Gold_Upto_Year', \n                         'Silver_Upto_Year', 'Bronze_Upto_Year','NOC_if_host']]\n    \n    def calculate_score(medals, host, participation_time, age):\n        \"\"\"\n        Calculate the score for medals (Gold, Silver, Bronze) based on host, participation time, and age.\n        \"\"\"\n        HOST_FACTOR = (1 - 27.18 / 55.80)  # Factor used when host = 1\n        if host == 1 and medals > 0:\n            return age * (8 ** medals - HOST_FACTOR) / participation_time\n        elif host == 0:\n            return age * (8 ** medals) / participation_time\n        else:\n            return 0\n    \n    final_df['Score_Gold'] = final_df.apply(\n        lambda row: calculate_score(\n            medals=row['Gold_Upto_Year'], \n            host=row['NOC_if_host'], \n            participation_time=row['Age_Proxy'], \n            age=row['Medal_Probability_at_Age']\n        ), axis=1\n    )\n    final_df['Score_Silver'] = final_df.apply(\n        lambda row: calculate_score(\n            medals=row['Silver_Upto_Year'], \n            host=row['NOC_if_host'], \n            participation_time=row['Age_Proxy'], \n            age=row['Medal_Probability_at_Age']\n        ), axis=1\n    )\n    \n    final_df['Score_Bronze'] = final_df.apply(\n        lambda row: calculate_score(\n            medals=row['Bronze_Upto_Year'], \n            host=row['NOC_if_host'], \n            participation_time=row['Age_Proxy'], \n            age=row['Medal_Probability_at_Age']\n        ), axis=1\n    )\n    aggregated_scores = final_df.groupby(['Year', 'NOC'], as_index=False)[\n        ['Score_Gold', 'Score_Silver', 'Score_Bronze']\n    ].mean()\n    \n    aggregated_scores = aggregated_scores.rename(columns={\n        'Score_Gold': 'Avg_Score_Gold',\n        'Score_Silver': 'Avg_Score_Silver',\n        'Score_Bronze': 'Avg_Score_Bronze'\n    })\n    \n    train = train.merge(\n        aggregated_scores,\n        on=['Year', 'NOC'],\n        how='left'\n    )\n    return train\n\n\ndef replace_noc_with_kmeans(train, n_clusters=5):\n    noc_medals = train.groupby('NOC')[['Gold', 'Silver', 'Bronze']].mean().reset_index()\n    noc_medals['Total'] = noc_medals['Gold'] + noc_medals['Silver'] + noc_medals['Bronze']\n    \n    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n    noc_medals['Cluster'] = kmeans.fit_predict(noc_medals[['Gold', 'Silver', 'Bronze', 'Total']])\n\n    cluster_means = noc_medals.groupby('Cluster')[['Gold', 'Silver', 'Bronze', 'Total']].mean().reset_index()\n    cluster_means = cluster_means.rename(columns={\n        'Gold': 'Cluster_Gold',\n        'Silver': 'Cluster_Silver',\n        'Bronze': 'Cluster_Bronze',\n        'Total': 'Cluster_Total'\n    })\n\n    noc_medals = noc_medals.merge(cluster_means, on='Cluster', how='left')\n\n    train = train.merge(\n        noc_medals[['NOC', 'Cluster_Gold', 'Cluster_Silver', 'Cluster_Bronze', 'Cluster_Total']],\n        on='NOC',\n        how='left'\n    )\n\n    return train\n\ndef plot_kmeans_comparison(train):\n    plt.figure(figsize=(15, 10))\n\n    plt.subplot(2, 2, 1)\n    sns.scatterplot(x='Gold', y='Cluster_Gold', data=train)\n    plt.title('Gold vs Cluster_Gold')\n    plt.xlabel('Original Gold')\n    plt.ylabel('Cluster_Gold')\n\n    plt.subplot(2, 2, 2)\n    sns.scatterplot(x='Silver', y='Cluster_Silver', data=train)\n    plt.title('Silver vs Cluster_Silver')\n    plt.xlabel('Original Silver')\n    plt.ylabel('Cluster_Silver')\n\n    plt.subplot(2, 2, 3)\n    sns.scatterplot(x='Bronze', y='Cluster_Bronze', data=train)\n    plt.title('Bronze vs Cluster_Bronze')\n    plt.xlabel('Original Bronze')\n    plt.ylabel('Cluster_Bronze')\n\n    plt.subplot(2, 2, 4)\n    sns.scatterplot(x=train['Gold'] + train['Silver'] + train['Bronze'], y='Cluster_Total', data=train)\n    plt.title('Total Medals vs Cluster_Total')\n    plt.xlabel('Original Total Medals')\n    plt.ylabel('Cluster_Total')\n\n    plt.tight_layout()\n    plt.show()\n\n\ndef encode_sport_code_by_events(train):\n    sport_event_sum = train.groupby('Sport_Code')['Number_of_Events'].sum().reset_index()\n    sport_event_sum.rename(columns={'Number_of_Events': 'Sum_of_Events'}, inplace=True)\n\n    sport_event_sum['Sum_of_Event'] = sport_event_sum['Sum_of_Events'] / 100\n\n    train = train.merge(sport_event_sum[['Sport_Code', 'Sum_of_Events']], on='Sport_Code', how='left')\n\n    return train\n\ndef calculate_and_plot_correlation(train):\n    train['Total'] = train['Gold'] + train['Silver'] + train['Bronze']\n\n    targets = ['Total', 'Gold', 'Silver', 'Bronze']\n    numerical_features = train.select_dtypes(include=['number']).columns.tolist()\n\n    corr_matrix = train[numerical_features].corr()[targets]\n\n    plt.figure(figsize=(8, 6))\n    sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n    plt.title('Correlation of Total, Gold, Silver, Bronze with Other Features')\n    plt.show()\n\n    return corr_matrix","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:40:13.255289Z","iopub.execute_input":"2025-01-28T04:40:13.255559Z","iopub.status.idle":"2025-01-28T04:40:13.300072Z","shell.execute_reply.started":"2025-01-28T04:40:13.255536Z","shell.execute_reply":"2025-01-28T04:40:13.298939Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = medal_count_for_each_sport(athletes)\ntrain = create_2028_rows(train)\ntrain = merge_hosts(train, hosts)\nprograms = add_2028_sports(programs, y_2028_sports)\ntrain = merge_programs(train,programs)\ntrain = add_Medal_EWA(train)\ntrain = create_scores(train, athletes)\n\ntrain[train['Year']==2024].sort_values(by=['Year','Gold'], ascending=[False,False])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:40:13.301687Z","iopub.execute_input":"2025-01-28T04:40:13.302027Z","iopub.status.idle":"2025-01-28T04:40:31.682996Z","shell.execute_reply.started":"2025-01-28T04:40:13.301995Z","shell.execute_reply":"2025-01-28T04:40:31.682029Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train = replace_noc_with_kmeans(train, n_clusters=5)\n\nplot_kmeans_comparison(train)\ntrain = encode_sport_code_by_events(train)\n\ncalculate_and_plot_correlation(train)\nplt.savefig(\"correlation_train.png\", dpi=300, bbox_inches='tight')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:40:31.684429Z","iopub.execute_input":"2025-01-28T04:40:31.684699Z","iopub.status.idle":"2025-01-28T04:40:33.920608Z","shell.execute_reply.started":"2025-01-28T04:40:31.684676Z","shell.execute_reply":"2025-01-28T04:40:33.919607Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**EDA**","metadata":{}},{"cell_type":"code","source":"athletes_effect = train.loc[:, ['Year', 'NOC', 'Gold', 'Silver','Bronze', 'Athlete_Count', 'Athlete_Proportion']].groupby(['Year', 'NOC']).sum().reset_index()\nathletes_effect['Total_Medals'] = athletes_effect['Gold'] + athletes_effect['Silver'] + athletes_effect['Bronze']\n\nselected_countries = ['USA', 'CHN']\nfiltered_data = athletes_effect[athletes_effect['NOC'].isin(selected_countries)]\n\nfig, axes = plt.subplots(len(selected_countries), 1, figsize=(10, 5 * len(selected_countries)))\n\nfor i, country in enumerate(selected_countries):\n    country_data = filtered_data[filtered_data['NOC'] == country]\n    axes[i].plot(country_data['Year'], country_data['Athlete_Count'], label='Athlete Count', marker='o')\n    axes[i].plot(country_data['Year'], country_data['Athlete_Proportion']*50, label='Athlete Proportion * 50', marker='s')\n    axes[i].plot(country_data['Year'], country_data['Total_Medals'], label='Total Medals', marker='^')\n    \n    axes[i].set_title(f'Trends for {country}')\n    axes[i].set_xlabel('Year')\n    axes[i].set_ylabel('Value')\n    axes[i].legend(loc='upper left')\n    axes[i].grid(True)\n\nplt.tight_layout()\n\nplt.show()\nplt.savefig(\"Correlation of (Athlete_Count and Athlete_Proportion) and Total_Medals.png\", dpi=300, bbox_inches='tight')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:40:33.921725Z","iopub.execute_input":"2025-01-28T04:40:33.922062Z","iopub.status.idle":"2025-01-28T04:40:34.756437Z","shell.execute_reply.started":"2025-01-28T04:40:33.922034Z","shell.execute_reply":"2025-01-28T04:40:34.755541Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"average_data = athletes_effect.groupby('Year').agg({\n    'Athlete_Count': 'mean',\n    'Athlete_Proportion': 'mean',\n    'Total_Medals': 'mean'\n}).reset_index()\n\ncorrelation_matrix = average_data[['Athlete_Count', 'Athlete_Proportion', 'Total_Medals']].corr()\nprint(\"Correlation matrix for averaged data:\")\nprint(correlation_matrix)\n\nmi = mutual_info_regression(average_data[['Athlete_Count', 'Athlete_Proportion']], average_data['Total_Medals'], random_state=0)\nmi_results = dict(zip(average_data[['Athlete_Count', 'Athlete_Proportion']].columns, mi))\n\nprint(\"\\nMutual Information for averaged data:\")\nfor feature, value in mi_results.items():\n    print(f\"  {feature} -> Total_Medals: {value:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:40:34.757278Z","iopub.execute_input":"2025-01-28T04:40:34.757534Z","iopub.status.idle":"2025-01-28T04:40:34.781430Z","shell.execute_reply.started":"2025-01-28T04:40:34.757512Z","shell.execute_reply":"2025-01-28T04:40:34.779913Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Prepare data for Host Effect EDA\ntrain_eda = train.groupby(['Year', 'NOC'])[['Gold', 'Silver', 'Bronze']].sum().sort_values(by=['Year', 'Gold', 'Silver', 'Bronze'], ascending=[False, False, False, False]).reset_index()\ntrain_eda = merge_hosts(train_eda, hosts)\ntrain_eda\n\ndf_new = train_eda.copy()\ndf_new['Total_Medals'] = df_new[['Gold', 'Silver', 'Bronze']].sum(axis=1)\n\nhost_data = df_new[df_new['NOC_if_host'] == 1]\nhost_medals = host_data.groupby('NOC')['Total_Medals'].mean().reset_index()\nhost_medals.columns = ['NOC', 'Host_Medals']\n\ncountry_avg_medals = df_new.groupby('NOC')[['Gold', 'Silver', 'Bronze']].mean().sum(axis=1).reset_index()\ncountry_avg_medals.columns = ['NOC', 'Avg_Medals']\n\nhistorical_medals = df_new.groupby(['NOC', 'Year'])['Total_Medals'].sum().reset_index()\n\nfinal_data = country_avg_medals.merge(host_medals, on='NOC', how='left').fillna(0)\nfinal_data = final_data.sort_values(by='Avg_Medals', ascending=False)\nfinal_data = final_data[final_data['Host_Medals'] > 0]\n\n# For each countries, Average Medal and Host Medal and all historical medals\nplt.figure(figsize=(15, 10))\nsns.scatterplot(\n    data=historical_medals[historical_medals['NOC'].isin(final_data['NOC'])],\n    x='Total_Medals',\n    y='NOC',\n    color='lightgray',\n    s=50,\n    label='Historical Medals',\n)\nsns.scatterplot(\n    data=final_data,\n    x='Avg_Medals',\n    y='NOC',\n    color='blue',\n    s=100,\n    label='Average Medals',\n)\nsns.scatterplot(\n    data=final_data,\n    x='Host_Medals',\n    y='NOC',\n    color='red',\n    s=100,\n    label='Host Medals',\n)\n\navg_host_medals = final_data['Host_Medals'].mean()\navg_total_medals = final_data['Avg_Medals'].mean()\n\nplt.axvline(avg_host_medals, color='red', linestyle='--', label=f'Average Host Medals: {avg_host_medals:.2f}')\nplt.axvline(avg_total_medals, color='blue', linestyle='--', label=f'Average Total Medals: {avg_total_medals:.2f}')\nplt.title('Effect of Hosting on Medal Counts (Excluding Non-Hosts)', fontsize=16, fontweight='bold')\nplt.xlabel('Medals', fontsize=12)\nplt.ylabel('Country (NOC)', fontsize=12)\nplt.legend()\nplt.tight_layout()\nplt.show()\nplt.savefig(\"Effect of Hosting on Medal Counts (Excluding Non-Hosts).png\", dpi=300, bbox_inches='tight')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:40:34.782553Z","iopub.execute_input":"2025-01-28T04:40:34.782894Z","iopub.status.idle":"2025-01-28T04:40:35.544429Z","shell.execute_reply.started":"2025-01-28T04:40:34.782864Z","shell.execute_reply":"2025-01-28T04:40:35.543343Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Total Medals for Countries Through Time\ncountries = ['USA', 'CHN']\nfiltered_data = df_new[df_new['NOC'].isin(countries)]\n\nfig, axes = plt.subplots(2, 1, figsize=(15, 12), sharex=True)\n\nfor i, country in enumerate(countries):\n    temp = filtered_data[filtered_data['NOC'] == country]\n    color = ['red' if is_host == 1 else 'black' for is_host in temp['NOC_if_host']]\n\n    axes[i].bar(temp['Year'], temp['Total_Medals'], width=3, color=color)\n    axes[i].set_title(f'Total Olympic Medals for {country}', fontsize=14)\n    axes[i].set_ylabel('Total Medals', fontsize=12)\n    axes[i].grid(axis='y', linestyle=':', linewidth=0.5, color='gray')\n\n    axes[i].spines['top'].set_visible(False)\n    axes[i].spines['right'].set_visible(False)\n\naxes[-1].set_xlabel('Year', fontsize=12)\nplt.tight_layout()\nplt.show()\nplt.savefig(\"Total Medals for Host and Not Host Years.png\", dpi=300, bbox_inches='tight')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:40:35.547070Z","iopub.execute_input":"2025-01-28T04:40:35.547376Z","iopub.status.idle":"2025-01-28T04:40:36.325208Z","shell.execute_reply.started":"2025-01-28T04:40:35.547350Z","shell.execute_reply":"2025-01-28T04:40:36.324088Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Gold, Silver, Bronze for countries in each year\nmedals_by_year = filtered_data.groupby(['Year', 'NOC'])[['Gold', 'Silver', 'Bronze']].sum().reset_index()\n\nhost_years = df_new[df_new['NOC_if_host'] == 1].groupby('NOC')['Year'].unique().reset_index()\nhost_years = {row['NOC']: row['Year'] for _, row in host_years.iterrows()}\n\nall_years = np.arange(medals_by_year['Year'].min(), medals_by_year['Year'].max() + 1, 4)\n\nfig, axes = plt.subplots(nrows=len(countries), ncols=1, figsize=(14, 10), sharex=True)\nbar_width = 0.2\n\nfor i, country in enumerate(countries):\n    country_data = medals_by_year[medals_by_year['NOC'] == country]\n    country_data_full = pd.DataFrame({'Year': all_years})\n    country_data_full = country_data_full.merge(country_data, on='Year', how='left').fillna(0)\n\n    years = country_data_full['Year']\n    gold = country_data_full['Gold']\n    silver = country_data_full['Silver']\n    bronze = country_data_full['Bronze']\n    \n    x = np.arange(len(years))\n    \n    axes[i].bar(x - bar_width, gold, width=bar_width, label='Gold', color='gold')\n    axes[i].bar(x, silver, width=bar_width, label='Silver', color='silver')\n    axes[i].bar(x + bar_width, bronze, width=bar_width, label='Bronze', color='peru')\n    \n    if country in host_years:\n        for year in host_years[country]:\n            if year in years.values:\n                year_index = np.where(years == year)[0][0]\n                axes[i].axvline(x=year_index, color='red', linestyle='--', linewidth=2, alpha=0.7, \n                                label='Host Year' if year == host_years[country][0] else \"\")\n    \n    axes[i].set_title(f'Medal Counts for {country}')\n    axes[i].set_ylabel('Number of Medals')\n    axes[i].set_xticks(x)\n    axes[i].set_xticklabels(years, rotation=90)\n    axes[i].legend()\n\naxes[-1].set_xlabel('Year')\nplt.tight_layout()\nplt.show()\nplt.savefig(\"Medals for Host and Not Host Years.png\", dpi=300, bbox_inches='tight')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:40:36.326976Z","iopub.execute_input":"2025-01-28T04:40:36.327259Z","iopub.status.idle":"2025-01-28T04:40:37.826128Z","shell.execute_reply.started":"2025-01-28T04:40:36.327236Z","shell.execute_reply":"2025-01-28T04:40:37.824934Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Statistic test\n#To determine whether hosting the Olympics has a statistically significant effect on medal counts, we conducted a hypothesis test comparing the total medals won during host and non-host years. Since the total medals data is positively skewed, we applied a log transformation (using np.log1p) to make the distribution more normal, which is a key assumption for the t-test. We filtered the dataset to include only countries that have hosted the Olympics at least once, ensuring a fair comparison between host and non-host years for the same set of countries. The data was then split into two groups: host years (NOC_if_host == 1) and non-host years (NOC_if_host == 0). After applying the log transformation, we performed an independent two-sample t-test to compare the means of the log-transformed total medals between the two groups. The null hypothesis (H₀) was that the means are equal (no host effect), while the alternative hypothesis (H₁) was that the means are not equal (host effect exists). We calculated key statistics, including the means, standard errors, and the standardized difference between means. The t-test yielded a very small p-value (p < 0.05), leading us to reject the null hypothesis and conclude that there is a statistically significant difference in medal counts between host and non-host years. This suggests a host effect, where countries tend to win more medals when hosting the Olympics. The log transformation was crucial to ensure the validity of the t-test by addressing the skewness in the data.\ndf_new['Total_Medals'] = df_new[['Gold', 'Silver', 'Bronze']].sum(axis=1)\n\ndf_new['Total_Medals_NaturalLog'] = np.log1p(df_new['Total_Medals'])  # log(1 + x) to handle zeros\n\nhost_countries = df_new[df_new['NOC_if_host'] == 1]['NOC'].unique()\ndf_filtered = df_new[df_new['NOC'].isin(host_countries)]\n\nhost_data = df_filtered[df_filtered['NOC_if_host'] == 1]\nnon_host_data = df_filtered[df_filtered['NOC_if_host'] == 0]\n\nnot_hosting_mean = non_host_data['Total_Medals_NaturalLog'].mean()\nhosting_mean = host_data['Total_Medals_NaturalLog'].mean()\n\nnot_hosting_std = non_host_data['Total_Medals_NaturalLog'].std()\nhosting_std = host_data['Total_Medals_NaturalLog'].std()\n\nnot_hosting_samples = non_host_data['Total_Medals_NaturalLog'].count()\nhosting_samples = host_data['Total_Medals_NaturalLog'].count()\n\nnot_hosting_std_error = not_hosting_std / np.sqrt(not_hosting_samples)\nhosting_std_error = hosting_std / np.sqrt(hosting_samples)\n\ndifference = hosting_mean - not_hosting_mean\ncombined_std_error = np.sqrt((not_hosting_std**2 / not_hosting_samples) + (hosting_std**2 / hosting_samples))\n\nstat, p = ttest_ind(non_host_data['Total_Medals_NaturalLog'], host_data['Total_Medals_NaturalLog'])\n\nprint(\"Key Statistics\")\nprint(f\"Mean Natural Log of Total Medals when Not Hosting: {not_hosting_mean:.3f}\")\nprint(f\"Mean Natural Log of Total Medals when Hosting: {hosting_mean:.3f}\")\nprint(f\"Standard Error of Natural Log of Total Medals when Not Hosting: {not_hosting_std_error:.3f}\")\nprint(f\"Standard Error of Natural Log of Total Medals when Hosting: {hosting_std_error:.3f}\")\nprint(f\"Standard Errors between means: {difference / combined_std_error:.3f}\")\n\nprint(\"\\nT-Test\")\nprint(f\"Statistics = {stat:.3f}, p-value = {p:.3f}\")\nif p < 0.05:\n    print(\"Different distributions (reject H0)\")\nelse:\n    print(\"Same distributions (fail to reject H0)\")\n\nplt.figure(figsize=(10, 6))\nsns.kdeplot(non_host_data['Total_Medals_NaturalLog'], label='Not Hosting', color='blue', shade=True, alpha=0.5)\nsns.kdeplot(host_data['Total_Medals_NaturalLog'], label='Hosting', color='red', shade=True, alpha=0.5)\nplt.axvline(not_hosting_mean, color='blue', linestyle='--', label='Not Hosting Mean')\nplt.axvline(hosting_mean, color='red', linestyle='--', label='Hosting Mean')\nplt.title('Distribution of Log-Transformed Total Medals: Host vs Non-Host Years')\nplt.xlabel('Log(Total Medals + 1)')\nplt.ylabel('Density')\nplt.legend()\nplt.show()\nplt.savefig(\"Distribution of Total Medals When Hosting and Not Hosting.png\", dpi=300, bbox_inches='tight')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:40:37.827205Z","iopub.execute_input":"2025-01-28T04:40:37.827492Z","iopub.status.idle":"2025-01-28T04:40:38.721288Z","shell.execute_reply.started":"2025-01-28T04:40:37.827465Z","shell.execute_reply":"2025-01-28T04:40:38.720258Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**Time Series Features and Features Selection**","metadata":{}},{"cell_type":"code","source":"athletes_effect = train.loc[:, ['Year', 'NOC', 'Gold', 'Silver','Bronze', 'Athlete_Count', 'Athlete_Proportion']].groupby(['Year', 'NOC']).sum().reset_index()\nathletes_effect['Total_Medals'] = athletes_effect['Gold'] + athletes_effect['Silver'] + athletes_effect['Bronze']\n\ngrouped_data = athletes_effect.groupby(['NOC']).apply(\n    lambda x: x.sort_values('Year')\n).reset_index(drop=True)\n\n# Shift Athlete_Count and Athlete_Proportion to get previous year's values\ngrouped_data['Prev_Athlete_Count'] = grouped_data.groupby(['NOC'])['Athlete_Count'].shift(1)\ngrouped_data['Prev_Athlete_Proportion'] = grouped_data.groupby(['NOC'])['Athlete_Proportion'].shift(1)\n\n# Drop rows with NaN values (due to shifting)\ngrouped_data = grouped_data.dropna()\n\n# Calculate correlation matrix for shifted data\ncorrelation_matrix = grouped_data[['Prev_Athlete_Count', 'Prev_Athlete_Proportion', 'Total_Medals']].corr()\nprint(\"Correlation matrix for shifted data:\")\nprint(correlation_matrix)\n\n\n# Calculate mutual information\nmi = mutual_info_regression(grouped_data[['Prev_Athlete_Count', 'Prev_Athlete_Proportion']], grouped_data['Total_Medals'], random_state=0)\nmi_results = dict(zip(grouped_data[['Prev_Athlete_Count', 'Prev_Athlete_Proportion']].columns, mi))\n\nprint(\"\\nMutual Information for shifted data:\")\nfor feature, value in mi_results.items():\n    print(f\"  {feature} -> Total_Medals: {value:.4f}\")\n\n\nsns.set(style=\"whitegrid\")\n\n# Scatter plot: Prev_Athlete_Count vs. Total_Medals\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x='Prev_Athlete_Count', y='Total_Medals', data=grouped_data, alpha=0.6)\nplt.title('Previous Year Athlete Count vs. Current Year Total Medals')\nplt.xlabel('Previous Year Athlete Count')\nplt.ylabel('Current Year Total Medals')\nplt.show()\nplt.savefig(\"Previous Year Athlete Count vs. Current Year Total Medals.png\", dpi=300, bbox_inches='tight')\n\n\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x='Prev_Athlete_Proportion', y='Total_Medals', data=grouped_data, alpha=0.6)\nplt.title('Previous Year Athlete Proportion vs. Current Year Total Medals')\nplt.xlabel('Previous Year Athlete Proportion')\nplt.ylabel('Current Year Total Medals')\nplt.show()\n\nplt.figure(figsize=(10, 6))\nsns.scatterplot(x='Prev_Athlete_Count', y='Athlete_Count', data=grouped_data, alpha=0.6)\nplt.title('Previous Year Athlete Count vs. Current Year Athlete Count')\nplt.xlabel('Previous Year Athlete Count')\nplt.ylabel('Current Year Athlete Count')\nplt.show()\nplt.savefig(\"Previous Year Athlete Count vs. Current Year Athlete Count.png\", dpi=300, bbox_inches='tight')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:40:38.722228Z","iopub.execute_input":"2025-01-28T04:40:38.722521Z","iopub.status.idle":"2025-01-28T04:40:40.084998Z","shell.execute_reply.started":"2025-01-28T04:40:38.722497Z","shell.execute_reply":"2025-01-28T04:40:40.083840Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def lagplot(x, y=None, lag=1, standardize=False, ax=None, **kwargs):\n    \"\"\"\n    Plot the relationship between a feature and its lagged version.\n    \"\"\"\n    from matplotlib.offsetbox import AnchoredText\n    x_ = x.shift(lag)\n    if standardize:\n        x_ = (x_ - x_.mean()) / x_.std()\n    if y is not None:\n        y_ = (y - y.mean()) / y.std() if standardize else y\n    else:\n        y_ = x\n    corr = y_.corr(x_)\n    if ax is None:\n        fig, ax = plt.subplots()\n    scatter_kws = dict(alpha=0.75, s=3)\n    line_kws = dict(color='C3')\n    ax = sns.regplot(x=x_, y=y_, scatter_kws=scatter_kws, line_kws=line_kws, lowess=True, ax=ax, **kwargs)\n    at = AnchoredText(f\"{corr:.2f}\", prop=dict(size=\"large\"), frameon=True, loc=\"upper left\")\n    at.patch.set_boxstyle(\"square, pad=0.0\")\n    ax.add_artist(at)\n    ax.set(title=f\"Lag {lag}\", xlabel=x_.name, ylabel=y_.name)\n    return ax\n    \ndef plot_lags(x, y=None, lags=6, nrows=1, lagplot_kwargs={}, **kwargs):\n    \"\"\"\n    Plot multiple lag plots for a feature.\n    \"\"\"\n    import math\n    kwargs.setdefault('nrows', nrows)\n    kwargs.setdefault('ncols', math.ceil(lags / nrows))\n    kwargs.setdefault('figsize', (kwargs['ncols'] * 2, nrows * 2 + 0.5))\n    fig, axs = plt.subplots(sharex=True, sharey=True, squeeze=False, **kwargs)\n    for ax, k in zip(fig.get_axes(), range(kwargs['nrows'] * kwargs['ncols'])):\n        if k + 1 <= lags:\n            ax = lagplot(x, y, lag=k + 1, ax=ax, **lagplot_kwargs)\n            ax.set_title(f\"Lag {k + 1}\", fontdict=dict(fontsize=14))\n            ax.set(xlabel=\"\", ylabel=\"\")\n        else:\n            ax.axis('off')\n    plt.setp(axs[-1, :], xlabel=x.name)\n    plt.setp(axs[:, 0], ylabel=y.name if y is not None else x.name)\n    fig.tight_layout(w_pad=0.1, h_pad=0.1)\n    return fig\n\n\ndef create_lagged_features_safely(train, features_to_lag, max_lag=2):\n    X = train.copy()\n\n    X = X.sort_values(by=['NOC', 'Sport_Code', 'Year'])\n\n    for feature in features_to_lag:\n        for lag in range(1, max_lag + 1):\n            lagged_series = X.groupby(['NOC', 'Sport_Code'])[feature].shift(lag)\n            lagged_series = lagged_series.groupby([X['NOC'], X['Sport_Code']]).ffill().bfill().fillna(0)\n            X[f'{feature}_lag{lag}'] = lagged_series\n\n    return X\n\ndef plot_partial_autocorrelation(series, lags=10):\n    \"\"\"\n    Plot the partial autocorrelation function (PACF) for a time series.\n    \"\"\"\n    fig, ax = plt.subplots(figsize=(8, 4))\n    plot_pacf(series, lags=lags, ax=ax, method='ywm')\n    plt.title(f'Partial Autocorrelation for {series.name}')\n    plt.xlabel('Lag')\n    plt.ylabel('Partial Autocorrelation')\n    plt.show()\n\n\nfeatures_to_lag = ['Athlete_Count', 'Athlete_Proportion', 'Medal_EWA', 'Avg_Score_Gold', 'Avg_Score_Silver', 'Avg_Score_Bronze', 'Gold', 'Silver', 'Bronze']\nX_original = create_lagged_features_safely(train, features_to_lag, max_lag=2)\n\nplot_lags(X_original['Gold'], lags=4, nrows=1)\nplt.show()\nplt.savefig(\"plot_lags_Gold.png\", dpi=300, bbox_inches='tight')\n\nplot_lags(X_original['Athlete_Proportion'], lags=4, nrows=1)\nplt.show()\nplt.savefig(\"plot_lags_Athlete_Proportion.png\", dpi=300, bbox_inches='tight')\n\nplot_lags(X_original['Medal_EWA'], lags=4, nrows=1)\nplt.show()\nplt.savefig(\"plot_lags_Medal_EWA.png\", dpi=300, bbox_inches='tight')\n\nplot_partial_autocorrelation(X_original['Gold'], lags=10)\nplt.savefig(\"partial_autocorrelation_Gold.png\", dpi=300, bbox_inches='tight')\nplot_partial_autocorrelation(X_original['Athlete_Proportion'], lags=10)\nplt.savefig(\"partial_autocorrelation_Athlete_Proportion.png\", dpi=300, bbox_inches='tight')\nplot_partial_autocorrelation(X_original['Medal_EWA'], lags=10)\nplt.savefig(\"partial_autocorrelation_Medal_EWA.png\", dpi=300, bbox_inches='tight')\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:40:40.086125Z","iopub.execute_input":"2025-01-28T04:40:40.086409Z","iopub.status.idle":"2025-01-28T04:41:52.243802Z","shell.execute_reply.started":"2025-01-28T04:40:40.086384Z","shell.execute_reply":"2025-01-28T04:41:52.242725Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"X_original = X_original[['Year', 'NOC', 'Sport_Code', 'Gold', 'Silver', 'Bronze', 'NOC_if_host',\n       'Number_of_Events', 'Cluster_Gold',\n       'Cluster_Silver', 'Cluster_Bronze', 'Cluster_Total', 'Sum_of_Events',\n       'Athlete_Count_lag1', 'Athlete_Count_lag2', 'Athlete_Proportion_lag1',\n       'Athlete_Proportion_lag2', 'Medal_EWA_lag1','Avg_Score_Gold_lag1', \n       'Avg_Score_Silver_lag1', 'Avg_Score_Bronze_lag1', \n       'Gold_lag1', 'Gold_lag2', 'Silver_lag1', 'Silver_lag2', 'Bronze_lag1',\n       'Bronze_lag2']]\nX_original = X_original.sort_values(by=['Year', 'Gold', 'Silver', 'Bronze'], ascending=[False, False, False, False])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:41:52.244854Z","iopub.execute_input":"2025-01-28T04:41:52.245212Z","iopub.status.idle":"2025-01-28T04:41:52.264373Z","shell.execute_reply.started":"2025-01-28T04:41:52.245184Z","shell.execute_reply":"2025-01-28T04:41:52.263151Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"calculate_and_plot_correlation(X_original)\nX_original = X_original.drop(['Total'], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:41:52.265458Z","iopub.execute_input":"2025-01-28T04:41:52.265882Z","iopub.status.idle":"2025-01-28T04:41:53.017613Z","shell.execute_reply.started":"2025-01-28T04:41:52.265850Z","shell.execute_reply":"2025-01-28T04:41:53.016419Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"test = X_original[X_original['Year']==2028].copy()\ntest_vis = test.copy()\ntest = test.drop(['Year', 'NOC', 'Sport_Code'], axis=1)\nX = X_original[X_original['Year']!=2028].copy()\nvis = X.copy()\nX = X.drop(['Year', 'NOC', 'Sport_Code'], axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:41:53.019038Z","iopub.execute_input":"2025-01-28T04:41:53.019324Z","iopub.status.idle":"2025-01-28T04:41:53.041016Z","shell.execute_reply.started":"2025-01-28T04:41:53.019300Z","shell.execute_reply":"2025-01-28T04:41:53.040072Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def random_search_hyperparameters():\n    return {\n        'n_layers': random.choice([2, 3, 4]),\n        'neurons': random.choice([64, 128, 256]),\n        'dropout_rate': random.uniform(0.1, 0.4),\n        'learning_rate': random.uniform(0.0001, 0.01)\n    }\n\ndef build_model(input_dim, n_layers, neurons, dropout_rate, learning_rate):\n    inputs = Input(shape=(input_dim,))\n    x = Dense(neurons, activation='relu')(inputs)\n    for _ in range(n_layers - 1):\n        residual = x\n        x = Dense(neurons, activation='relu')(x)\n        x = BatchNormalization()(x)\n        x = Dropout(dropout_rate)(x)\n        x = Add()([x, residual])\n    x = Dense(32, activation='relu')(x)\n    outputs = Dense(3, activation='linear')(x)\n    model = Model(inputs, outputs)\n    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='mean_squared_error', metrics=['mae'])\n    return model\n\ndef random_search(X_train, y_train, X_val, y_val):\n    best_r2 = -np.inf\n    best_params = None\n    best_model = None\n\n    for _ in range(10):\n        params = random_search_hyperparameters()\n        model = build_model(\n            input_dim=X_train.shape[1],\n            n_layers=params['n_layers'],\n            neurons=params['neurons'],\n            dropout_rate=params['dropout_rate'],\n            learning_rate=params['learning_rate']\n        )\n\n        early_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=0)\n\n        history = model.fit(\n            X_train, y_train,\n            validation_split=0.2,\n            epochs=100,\n            batch_size=32,\n            verbose=0,\n            callbacks=[early_stop]\n        )\n\n        y_pred = model.predict(X_val)\n        r2_gold = r2_score(y_val['Gold'], y_pred[:, 0])\n        r2_silver = r2_score(y_val['Silver'], y_pred[:, 1])\n        r2_bronze = r2_score(y_val['Bronze'], y_pred[:, 2])\n        avg_r2 = (r2_gold + r2_silver + r2_bronze) / 3\n\n        if avg_r2 > best_r2:\n            best_r2 = avg_r2\n            best_params = params\n            best_model = model\n\n    return best_model, best_params, best_r2\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X.drop(columns=['Gold', 'Silver', 'Bronze']),\n    X[['Gold', 'Silver', 'Bronze']],\n    test_size=0.2,\n    random_state=42\n)\n\nscaler_X = StandardScaler()\nscaler_y = StandardScaler()\nX_train = scaler_X.fit_transform(X_train)\nX_val = scaler_X.transform(X_val)\ny_train_scaled = scaler_y.fit_transform(y_train)\ny_val_scaled = scaler_y.transform(y_val)\n\n#model, best_params, best_r2 = random_search(X_train, y_train, X_val, y_val)\nbest_params = {'n_layers': 4,\n  'neurons': 64,\n  'dropout_rate': 0.10750322656680009,\n  'learning_rate': 0.002822790251854281} # R2 is 0.7682101986647364\n\nmodel = build_model(\n    input_dim=X_train.shape[1],\n    n_layers=best_params['n_layers'],\n    neurons=best_params['neurons'],\n    dropout_rate=best_params['dropout_rate'],\n    learning_rate=best_params['learning_rate']\n)\n\nearly_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n\nhistory = model.fit(\n    X_train, y_train,\n    validation_data=(X_val, y_val),\n    epochs=100,\n    batch_size=32,\n    verbose=1,\n    callbacks=[early_stop]\n)\n\ny_pred_final = model.predict(X_val)\nr2_gold_final = r2_score(y_val['Gold'], y_pred_final[:, 0])\nr2_silver_final = r2_score(y_val['Silver'], y_pred_final[:, 1])\nr2_bronze_final = r2_score(y_val['Bronze'], y_pred_final[:, 2])\n\nprint(f\"Final R² for Gold: {r2_gold_final:.4f}\")\nprint(f\"Final R² for Silver: {r2_silver_final:.4f}\")\nprint(f\"Final R² for Bronze: {r2_bronze_final:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:41:53.042195Z","iopub.execute_input":"2025-01-28T04:41:53.042484Z","iopub.status.idle":"2025-01-28T04:42:37.044966Z","shell.execute_reply.started":"2025-01-28T04:41:53.042462Z","shell.execute_reply":"2025-01-28T04:42:37.043746Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_pred_all_scaled = model.predict(scaler_X.transform(X.drop(['Gold', 'Silver', 'Bronze'], axis=1)))\ny_pred_all = scaler_y.inverse_transform(y_pred_all_scaled)\nvis['Predicted_Gold'] = y_pred_all[:, 0]\nvis['Predicted_Silver'] = y_pred_all[:, 1]\nvis['Predicted_Bronze'] = y_pred_all[:, 2]\n\nvis = vis[['Year', 'NOC', 'Sport_Code', 'Gold', 'Silver', 'Bronze', 'Predicted_Gold', 'Predicted_Silver', 'Predicted_Bronze']]\n\nr2_gold_lag = r2_score(X['Gold_lag1'], X['Gold'])\nr2_silver_lag = r2_score(X['Silver_lag1'], X['Silver'])\nr2_bronze_lag = r2_score(X['Bronze_lag1'], X['Bronze'])\nr2_total_lag = r2_score(\n    X[['Gold_lag1', 'Silver_lag1', 'Bronze_lag1']].sum(axis=1),\n    X[['Gold', 'Silver', 'Bronze']].sum(axis=1)\n)\nprint(f\"R² for Gold (Lagged Values): {r2_gold_lag:.4f}\")\nprint(f\"R² for Silver (Lagged Values): {r2_silver_lag:.4f}\")\nprint(f\"R² for Bronze (Lagged Values): {r2_bronze_lag:.4f}\")\nprint(f\"R² for Total Medals (Lagged Values): {r2_total_lag:.4f}\\n\")\n\nr2_gold_sport = r2_score(vis['Gold'], vis['Predicted_Gold'])\nr2_silver_sport = r2_score(vis['Silver'], vis['Predicted_Silver'])\nr2_bronze_sport = r2_score(vis['Bronze'], vis['Predicted_Bronze'])\nr2_total_sport = r2_score(\n    vis[['Gold', 'Silver', 'Bronze']].sum(axis=1),\n    vis[['Predicted_Gold', 'Predicted_Silver', 'Predicted_Bronze']].sum(axis=1)\n)\nprint(f\"R² for Gold (Year, NOC, Sport_Code): {r2_gold_sport:.4f}\")\nprint(f\"R² for Silver (Year, NOC, Sport_Code): {r2_silver_sport:.4f}\")\nprint(f\"R² for Bronze (Year, NOC, Sport_Code): {r2_bronze_sport:.4f}\")\nprint(f\"R² for Total Medals (Year, NOC, Sport_Code): {r2_total_sport:.4f}\\n\")\n\naggregated_vis = vis.groupby(['Year', 'NOC']).sum().reset_index()\nr2_gold = r2_score(aggregated_vis['Gold'], aggregated_vis['Predicted_Gold'])\nr2_silver = r2_score(aggregated_vis['Silver'], aggregated_vis['Predicted_Silver'])\nr2_bronze = r2_score(aggregated_vis['Bronze'], aggregated_vis['Predicted_Bronze'])\nr2_total_year_noc = r2_score(\n    aggregated_vis[['Gold', 'Silver', 'Bronze']].sum(axis=1),\n    aggregated_vis[['Predicted_Gold', 'Predicted_Silver', 'Predicted_Bronze']].sum(axis=1)\n)\nprint(f\"R² for Gold (Year, NOC): {r2_gold:.4f}\")\nprint(f\"R² for Silver (Year, NOC): {r2_silver:.4f}\")\nprint(f\"R² for Bronze (Year, NOC): {r2_bronze:.4f}\")\nprint(f\"R² for Total Medals (Year, NOC): {r2_total_year_noc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:42:37.046079Z","iopub.execute_input":"2025-01-28T04:42:37.046407Z","iopub.status.idle":"2025-01-28T04:42:38.516335Z","shell.execute_reply.started":"2025-01-28T04:42:37.046371Z","shell.execute_reply":"2025-01-28T04:42:38.514999Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"usa_data = aggregated_vis[aggregated_vis['NOC'] == 'USA']\nusa_data['Total'] = usa_data[['Gold', 'Silver', 'Bronze']].sum(axis=1)\nusa_data['Predicted_Total'] = usa_data[['Predicted_Gold', 'Predicted_Silver', 'Predicted_Bronze']].sum(axis=1)\n\nplt.figure(figsize=(10, 6))\nplt.plot(usa_data['Year'], usa_data['Gold'], label='Actual Gold', marker='o')\nplt.plot(usa_data['Year'], usa_data['Predicted_Gold'], label='Predicted Gold', marker='o', linestyle='--')\n\nplt.plot(usa_data['Year'], usa_data['Silver'], label='Actual Silver', marker='s')\nplt.plot(usa_data['Year'], usa_data['Predicted_Silver'], label='Predicted Silver', marker='s', linestyle='--')\n\nplt.plot(usa_data['Year'], usa_data['Bronze'], label='Actual Bronze', marker='^')\nplt.plot(usa_data['Year'], usa_data['Predicted_Bronze'], label='Predicted Bronze', marker='^', linestyle='--')\n\nplt.plot(usa_data['Year'], usa_data['Total'], label='Actual Total', marker='D', color='black')\nplt.plot(usa_data['Year'], usa_data['Predicted_Total'], label='Predicted Total', marker='D', linestyle='--', color='gray')\n\nplt.title('USA Medals: Actual vs Predicted')\nplt.xlabel('Year')\nplt.ylabel('Medal Count')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:42:38.517467Z","iopub.execute_input":"2025-01-28T04:42:38.517853Z","iopub.status.idle":"2025-01-28T04:42:38.970130Z","shell.execute_reply.started":"2025-01-28T04:42:38.517815Z","shell.execute_reply":"2025-01-28T04:42:38.968904Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"usa_data['Residual_Gold'] = usa_data['Gold'] - usa_data['Predicted_Gold']\nusa_data['Residual_Silver'] = usa_data['Silver'] - usa_data['Predicted_Silver']\nusa_data['Residual_Bronze'] = usa_data['Bronze'] - usa_data['Predicted_Bronze']\nusa_data['Residual_Total'] = usa_data['Total'] - usa_data['Predicted_Total']\n\nstd_gold = usa_data['Residual_Gold'].std()\nstd_silver = usa_data['Residual_Silver'].std()\nstd_bronze = usa_data['Residual_Bronze'].std()\nstd_total = usa_data['Residual_Total'].std()\n\nconfidence_factor = 1.96  # For 95% confidence interval\nusa_data['Gold_Lower'] = usa_data['Predicted_Gold'] - confidence_factor * std_gold\nusa_data['Gold_Upper'] = usa_data['Predicted_Gold'] + confidence_factor * std_gold\n\nusa_data['Silver_Lower'] = usa_data['Predicted_Silver'] - confidence_factor * std_silver\nusa_data['Silver_Upper'] = usa_data['Predicted_Silver'] + confidence_factor * std_silver\n\nusa_data['Bronze_Lower'] = usa_data['Predicted_Bronze'] - confidence_factor * std_bronze\nusa_data['Bronze_Upper'] = usa_data['Predicted_Bronze'] + confidence_factor * std_bronze\n\nusa_data['Total_Lower'] = usa_data['Predicted_Total'] - confidence_factor * std_total\nusa_data['Total_Upper'] = usa_data['Predicted_Total'] + confidence_factor * std_total\n\nplt.figure(figsize=(12, 8))\n\nplt.plot(usa_data['Year'], usa_data['Gold'], label='Actual Gold', marker='o', color='gold')\nplt.plot(usa_data['Year'], usa_data['Predicted_Gold'], label='Predicted Gold', marker='o', linestyle='--', color='orange')\n\nplt.plot(usa_data['Year'], usa_data['Silver'], label='Actual Silver', marker='s', color='silver')\nplt.plot(usa_data['Year'], usa_data['Predicted_Silver'], label='Predicted Silver', marker='s', linestyle='--', color='gray')\n\nplt.plot(usa_data['Year'], usa_data['Bronze'], label='Actual Bronze', marker='^', color='brown')\nplt.plot(usa_data['Year'], usa_data['Predicted_Bronze'], label='Predicted Bronze', marker='^', linestyle='--', color='darkred')\n\nplt.plot(usa_data['Year'], usa_data['Total'], label='Actual Total', marker='D', color='black')\nplt.plot(usa_data['Year'], usa_data['Predicted_Total'], label='Predicted Total', marker='D', linestyle='--', color='gray')\n\nplt.fill_between(usa_data['Year'], usa_data['Gold_Lower'], usa_data['Gold_Upper'], color='orange', alpha=0.2, label='Gold Interval')\nplt.fill_between(usa_data['Year'], usa_data['Silver_Lower'], usa_data['Silver_Upper'], color='gray', alpha=0.2, label='Silver Interval')\nplt.fill_between(usa_data['Year'], usa_data['Bronze_Lower'], usa_data['Bronze_Upper'], color='brown', alpha=0.2, label='Bronze Interval')\nplt.fill_between(usa_data['Year'], usa_data['Total_Lower'], usa_data['Total_Upper'], color='black', alpha=0.2, label='Total Interval')\n\nplt.title('USA Medals: Actual vs Predicted with Prediction Intervals')\nplt.xlabel('Year')\nplt.ylabel('Medal Count')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:42:38.971257Z","iopub.execute_input":"2025-01-28T04:42:38.971633Z","iopub.status.idle":"2025-01-28T04:42:39.535462Z","shell.execute_reply.started":"2025-01-28T04:42:38.971601Z","shell.execute_reply":"2025-01-28T04:42:39.534207Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Predict test\ny_test_pred_scaled = model.predict(scaler_X.transform(test.drop(['Gold', 'Silver', 'Bronze'], axis=1)))\ny_test_pred = scaler_y.inverse_transform(y_test_pred_scaled)\ntest_vis['Gold'] = y_test_pred[:, 0]\ntest_vis['Silver'] = y_test_pred[:, 1]\ntest_vis['Bronze'] = y_test_pred[:, 2]\ntest_vis","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:42:39.536698Z","iopub.execute_input":"2025-01-28T04:42:39.537179Z","iopub.status.idle":"2025-01-28T04:42:39.827645Z","shell.execute_reply.started":"2025-01-28T04:42:39.537131Z","shell.execute_reply":"2025-01-28T04:42:39.826413Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Medal for each (Year, NOC, Sport), and medal for each (Year, NOC)\nmedal_sport = train[train['Year']!=2028].copy()\nmedal_sport = medal_sport[['Year', 'NOC', 'Sport_Code', 'Gold', 'Silver', 'Bronze']].copy()\ntest_vis = test_vis[['Year', 'NOC', 'Sport_Code', 'Gold', 'Silver', 'Bronze']].copy()\nmedal_sport = pd.concat([test_vis, medal_sport], ignore_index=True)\nmedal_sport['Total'] = medal_sport[['Gold', 'Silver', 'Bronze']].sum(axis=1)\nmedal_country = medal_sport.groupby(['Year', 'NOC'])[['Gold', 'Silver', 'Bronze', 'Total']].sum().reset_index()\nmedal_country","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:42:39.828725Z","iopub.execute_input":"2025-01-28T04:42:39.829072Z","iopub.status.idle":"2025-01-28T04:42:39.868467Z","shell.execute_reply.started":"2025-01-28T04:42:39.829039Z","shell.execute_reply":"2025-01-28T04:42:39.867252Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"medal_change = medal_country.pivot_table(index='NOC', columns='Year', values=['Gold', 'Total'], aggfunc='sum').reset_index()\n\nmedal_change['Gold_Change'] = medal_change[('Gold', 2028)] - medal_change[('Gold', 2024)]\nmedal_change['Total_Change'] = medal_change[('Total', 2028)] - medal_change[('Total', 2024)]\n\ntop_2_gold_max = medal_change.nlargest(2, 'Gold_Change')[['NOC', 'Gold_Change']]\ntop_2_gold_min = medal_change.nsmallest(2, 'Gold_Change')[['NOC', 'Gold_Change']]\ntop_2_total_max = medal_change.nlargest(2, 'Total_Change')[['NOC', 'Total_Change']]\ntop_2_total_min = medal_change.nsmallest(2, 'Total_Change')[['NOC', 'Total_Change']]\n\nselected_nocs = pd.concat([\n    top_2_gold_max['NOC'], \n    top_2_gold_min['NOC'], \n    top_2_total_max['NOC'], \n    top_2_total_min['NOC']\n]).unique()\n\ngold_improve = top_2_gold_max['NOC'].tolist()\ngold_decline = top_2_gold_min['NOC'].tolist()\ntotal_improve = top_2_total_max['NOC'].tolist()\ntotal_decline = top_2_total_min['NOC'].tolist()\n\nprint(f\"Top 2 improvement in Gold: {', '.join(gold_improve)}\")\nprint(f\"Top 2 decline in Gold: {', '.join(gold_decline)}\")\nprint(f\"Top 2 improvement in Total: {', '.join(total_improve)}\")\nprint(f\"Top 2 decline in Total: {', '.join(total_decline)}\")\n\nfor noc in selected_nocs:\n    noc_data = medal_country[medal_country['NOC'] == noc]\n    plt.figure(figsize=(10, 6))\n    plt.plot(noc_data['Year'], noc_data['Gold'], label='Gold', marker='o', color='gold')\n    plt.plot(noc_data['Year'], noc_data['Total'], label='Total', marker='s', color='black')\n    plt.title(f'Medal Counts for {noc} (Gold and Total Across All Years)')\n    plt.xlabel('Year')\n    plt.ylabel('Medal Count')\n    plt.xticks(sorted(noc_data['Year'].unique()), rotation=90)\n    plt.legend()\n    plt.grid(True)\n    plt.tight_layout()\n    plt.show()\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:42:39.869411Z","iopub.execute_input":"2025-01-28T04:42:39.869681Z","iopub.status.idle":"2025-01-28T04:42:42.401711Z","shell.execute_reply.started":"2025-01-28T04:42:39.869657Z","shell.execute_reply":"2025-01-28T04:42:42.400545Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 1.2. Odds of winning the first Medal\nSEED = 42\nnp.random.seed(SEED)\nrandom.seed(SEED)\ntf.random.set_seed(SEED)\n\nX_class_test = X_original[X_original['Year'] == 2028].copy()\nX_class_test_vis = X_class_test.copy()\nX_class_test['Total'] = X_class_test[['Gold', 'Silver', 'Bronze']].sum(axis=1)\nX_class_test['Total'] = np.where(X_class_test['Total'] > 0, 1, 0)\nX_class_test = X_class_test.drop(['Year', 'NOC', 'Sport_Code', 'Gold', 'Silver', 'Bronze'], axis=1)\nX_class = X_original[X_original['Year'] != 2028].copy()\nvis_class = X_class.copy()\nX_class['Total'] = X_class[['Gold', 'Silver', 'Bronze']].sum(axis=1)\nX_class['Total'] = np.where(X_class['Total'] > 0, 1, 0)\nX_class = X_class.drop(['Year', 'NOC', 'Sport_Code', 'Gold', 'Silver', 'Bronze'], axis=1)\n\ny_class = X_class['Total']\nX_class = X_class.drop(['Total'], axis=1)\n\ny_class_test = X_class_test['Total']\nX_class_test = X_class_test.drop(['Total'], axis=1)\n\nX_class_train, X_class_val, y_class_train, y_class_val = train_test_split(\n    X_class, y_class, test_size=0.2, random_state=42, stratify=y_class\n)\n\nscaler = StandardScaler()\nX_class_train = scaler.fit_transform(X_class_train)\nX_class_val = scaler.transform(X_class_val)\nX_class_test = scaler.transform(X_class_test)\n\ny_class_train = y_class_train.astype(int)\nclass_weight_0 = sum(y_class_train == 0) / len(y_class_train)\nclass_weight_1 = sum(y_class_train == 1) / len(y_class_train)\nclass_weights_dict = {0: class_weight_0, 1: class_weight_1}\n\nclass_model = Sequential([\n    Dense(64, activation='relu'),\n    Dropout(0.3),\n    Dense(32, activation='relu'),\n    Dropout(0.2),\n    Dense(1, activation='sigmoid')  # Binary classification\n])\n\nclass_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nearly_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n\nhistory = class_model.fit(\n    X_class_train, y_class_train,\n    validation_data=(X_class_val, y_class_val),\n    epochs=100,\n    batch_size=32,\n    verbose=1,\n    callbacks=[early_stop]\n)\n\ny_val_pred_prob = class_model.predict(X_class_val)\ny_val_pred_binary = (y_val_pred_prob > 0.5).astype(int)\n\nprint(\"Validation Classification Report:\")\nprint(classification_report(y_class_val, y_val_pred_binary))\n\ny_test_pred_prob = class_model.predict(X_class_test)\ny_test_pred_binary = (y_test_pred_prob > 0.5).astype(int)\n\nX_class_test_vis['Predicted_Medal'] = y_test_pred_binary\nX_class_test_vis['Prediction_Probability'] = list(zip(1 - y_test_pred_prob.flatten(), y_test_pred_prob.flatten()))\n\ntrain['Total'] = train[['Gold', 'Silver', 'Bronze']].sum(axis=1)\nnoc_year_totals = (\n    train[['Year', 'NOC', 'Total']]\n    .groupby(['Year', 'NOC'], as_index=False)\n    .sum().reset_index()\n)\nno_medal_nocs = (\n    noc_year_totals.groupby('NOC')['Total']\n    .sum()\n    .reset_index()\n)\nno_medal_nocs = no_medal_nocs[no_medal_nocs['Total'] == 0]\nparticipated_nocs = train[train['Year'] > 2016]['NOC'].unique()\nno_medal_participated_nocs = no_medal_nocs[no_medal_nocs['NOC'].isin(participated_nocs)]\nselected_columns = ['Year', 'NOC', 'Sport_Code', 'Predicted_Medal', 'Prediction_Probability']\nfiltered_predictions = X_class_test_vis[X_class_test_vis['NOC'].isin(no_medal_participated_nocs['NOC'])][selected_columns]\n\ncountry_probabilities = filtered_predictions.groupby('NOC')['Prediction_Probability'].apply(\n    lambda probs: 1 - np.prod([1 - prob[1] for prob in probs])\n).reset_index()\n\ncountry_probabilities.columns = ['NOC', 'Overall_Probability']\ncountry_probabilities['Odds_in_Percent'] = country_probabilities['Overall_Probability'] * 100 / (1 - country_probabilities['Overall_Probability'])\ncountry_probabilities = country_probabilities.sort_values(by='Odds_in_Percent', ascending=False)\ncountry_probabilities","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:42:42.404970Z","iopub.execute_input":"2025-01-28T04:42:42.405266Z","iopub.status.idle":"2025-01-28T04:43:35.081825Z","shell.execute_reply.started":"2025-01-28T04:42:42.405239Z","shell.execute_reply":"2025-01-28T04:43:35.080594Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Great Coach\ntrain = train[train['Year']!=2028]\nA = train.copy()\nA.drop(['Year', 'NOC', 'NOC_host', 'Sport_Code'], axis=1, inplace=True)\nA = A.dropna()\ntrain = train.loc[A.index].reset_index(drop=True)\nA = A.reset_index(drop=True)\n\nX_A = A.drop(['Gold', 'Silver', 'Bronze'], axis=1)\ny_A = A[['Gold', 'Silver', 'Bronze']]\n\nX_A_train, X_A_val, y_A_train, y_A_val = train_test_split(\n    X_A, y_A, test_size=0.2, random_state=42\n)\nscaler_A_X = StandardScaler()\nscaler_A_y = StandardScaler()\n\nX_A_train = scaler_A_X.fit_transform(X_A_train)\nX_A_val = scaler_A_X.transform(X_A_val)\n\ny_A_train_scaled = scaler_A_y.fit_transform(y_A_train)\ny_A_val_scaled = scaler_A_y.transform(y_A_val)\n\nA_model = Sequential([\n    Dense(128, activation='relu', input_dim=X_A_train.shape[1]),\n    Dropout(0.3),\n    Dense(64, activation='relu'),\n    Dropout(0.2),\n    Dense(3, activation='linear')\n])\n\nA_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n\nearly_stop = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n\nhistory = A_model.fit(\n    X_A_train, y_A_train_scaled,\n    validation_data=(X_A_val, y_A_val_scaled),\n    epochs=100,\n    batch_size=32,\n    verbose=1,\n    callbacks=[early_stop]\n)\n\nX_A_scaled = scaler_A_X.transform(X_A)\ny_A_pred_scaled = A_model.predict(X_A_scaled)\ny_A_pred = scaler_A_y.inverse_transform(y_A_pred_scaled)\n\ntrain['Predicted_Gold'] = y_A_pred[:, 0]\ntrain['Predicted_Silver'] = y_A_pred[:, 1]\ntrain['Predicted_Bronze'] = y_A_pred[:, 2]\n\n# Prepare the dataset for Great Coach Effect analysis\ngreat_coach = train[['Year', 'NOC', 'Sport_Code', 'Gold', 'Predicted_Gold']].copy()\ngreat_coach['Gold_Change'] = great_coach['Gold'] - great_coach['Predicted_Gold']\n\n# Sort by the largest positive difference\ngold_diff = great_coach.sort_values(by='Gold_Change', ascending=False)\n\n# Select the top NOCs with the highest true-predicted difference, ensuring one per NOC\ntop_3_gold_changes = gold_diff.drop_duplicates(subset=['NOC'], keep='first').nlargest(3, 'Gold_Change')\n\n# Plot historical data for these combinations\nfor _, row in top_3_gold_changes.iterrows():\n    noc = row['NOC']\n    sport = row['Sport_Code']\n    sport_data = great_coach[\n        (great_coach['NOC'] == noc) & (great_coach['Sport_Code'] == sport)\n    ]\n    \n    plt.figure(figsize=(12, 6))\n    plt.plot(sport_data['Year'], sport_data['Gold'], label=f'{noc} - {sport} (True Gold)', marker='o', color='blue')\n    plt.plot(sport_data['Year'], sport_data['Predicted_Gold'], label=f'{noc} - {sport} (Predicted Gold)', marker='x', color='orange')\n    plt.axvline(x=row['Year'], color='red', linestyle='--', label=f\"Significant Gold Change ({row['Year']})\")\n    plt.title(f'Great Coach Effect for {noc} in {sport}')\n    plt.xlabel('Year')\n    plt.ylabel('Gold Count')\n    plt.xticks(sorted(sport_data['Year'].unique()), rotation=90)\n    plt.grid(True)\n    plt.legend()\n    plt.tight_layout()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:43:35.083236Z","iopub.execute_input":"2025-01-28T04:43:35.083583Z","iopub.status.idle":"2025-01-28T04:44:15.099975Z","shell.execute_reply.started":"2025-01-28T04:43:35.083552Z","shell.execute_reply":"2025-01-28T04:44:15.098885Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Filter the dataset for the USA\nusa_test_vis = test_vis[test_vis['NOC'] == 'USA'].copy()\n\n# Calculate the sum of actual medals for Gold, Silver, and Bronze\nusa_actual_gsb = usa_test_vis[['Gold', 'Silver', 'Bronze']].sum()\n\n# Add a total medals column (Gold + Silver + Bronze)\nusa_actual_gsb['Total'] = usa_actual_gsb['Gold'] + usa_actual_gsb['Silver'] + usa_actual_gsb['Bronze']\n\n# Create a summary DataFrame for the results\nusa_gsb_summary_with_total = pd.DataFrame({\n    'Medal Type': ['Gold', 'Silver', 'Bronze', 'Total'],\n    'Medals': [\n        usa_actual_gsb['Gold'],\n        usa_actual_gsb['Silver'],\n        usa_actual_gsb['Bronze'],\n        usa_actual_gsb['Total']\n    ]\n})\nusa_gsb_summary_with_total","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-28T04:44:15.101374Z","iopub.execute_input":"2025-01-28T04:44:15.101692Z","iopub.status.idle":"2025-01-28T04:44:15.116370Z","shell.execute_reply.started":"2025-01-28T04:44:15.101654Z","shell.execute_reply":"2025-01-28T04:44:15.115319Z"}},"outputs":[],"execution_count":null}]}